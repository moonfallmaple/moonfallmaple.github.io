<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo.png"/>
	<link rel="shortcut icon" href="/img/logo.png">
	
			    <title>
    Sunrise Jade
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="Rock sunrisejade" />
    
    	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
</head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">月靖天阙</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">Home</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">Category</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/Data-Analysis/">Data-Analysis</a>
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/tags/" title="Tag">
		                Tag
		            </a>
		        </li>
		        
		        <li>
		            <a href="https://www.linkedin.com/in/jane-shan-a50170142/" title="Resume">
		                Resume
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/sunrisejade" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height:8rem;background-image: url();background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 2rem 4rem 2rem 4rem ;"><h2 >Titanic(2)</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 2rem 4rem 2rem 4rem ;">
                <h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li>1 模型融合方法</li>
<li>2 Titanic Stacking 构建</li>
</ul>
<a id="more"></a>
<h2 id="1-模型融合方法"><a href="#1-模型融合方法" class="headerlink" title="1 模型融合方法"></a>1 模型融合方法</h2><h3 id="一、Voting"><a href="#一、Voting" class="headerlink" title="一、Voting"></a>一、Voting</h3><p>对于一个二分类问题，采取投票制的方法，投票多者确定为最终的分类。</p>
<h3 id="二、Averaging"><a href="#二、Averaging" class="headerlink" title="二、Averaging"></a>二、Averaging</h3><p>对于回归问题，一个简单直接的思路是取平均。稍稍改进的方法是进行加权平均。权值可以用排序的方法确定，举个例子，比如A、B、C三种基本模型，模型效果进行排名，假设排名分别是1，2，3，那么给这三个模型赋予的权值分别是3/6、2/6、1/6<br>这两种方法看似简单，其实后面的高级算法也可以说是基于此而产生的，Bagging或者Boosting都是一种把许多弱分类器这样融合成强分类器的思想。</p>
<h3 id="三、Bagging"><a href="#三、Bagging" class="headerlink" title="三、Bagging"></a>三、Bagging</h3><p>就是采用有放回的方式进行抽样，用抽样的样本建立子模型,对子模型进行训练，这个过程重复多次，最后进行融合。大概分为这样两步：<br>重复K次</p>
<p>有放回地重复抽样建模<br>训练子模型</p>
<p>2.模型融合<br>分类问题：voting</p>
<p>回归问题：average<br>Bagging算法不用我们自己实现，随机森林就是基于Bagging算法的一个典型例子，采用的基分类器是决策树。R和python都集成好了，直接调用</p>
<h3 id="四、Boosting"><a href="#四、Boosting" class="headerlink" title="四、Boosting"></a>四、Boosting</h3><p>Bagging算法可以并行处理，而Boosting的思想是一种迭代的方法，每一次训练的时候都更加关心分类错误的样例，给这些分类错误的样例增加更大的权重，下一次迭代的目标就是能够更容易辨别出上一轮分类错误的样例。最终将这些弱分类器进行加权相加。</p>
<h3 id="五、-Stacking原理"><a href="#五、-Stacking原理" class="headerlink" title="五、 Stacking原理"></a>五、 Stacking原理</h3><p>Stacking是层状结构的，以常见的两层为例，第一层是不同的基模型，而第二层是以上层基模型为输入数据的分类器。注意点：第一阶段的候选模型追求的是‘准而不同’，不同模型相对不关联。<br>先从一种“错误”但是容易懂的Stacking方法讲起。假设我们有3个基模型M1、M2、M3,用于第一阶段的训练，另一个模型M4用于第二阶段的训练。</p>
<ol>
<li>基模型M1，对训练集train训练，然后用于预测train和test的标签列，分别是P1，T1</li>
</ol>
<img src="/2018/06/29/Titanic_3/pic1.png" title="This is an example image">
<p>对于M2和M3，重复相同的工作，这样也得到P2，T2,P3,T3。</p>
<ol start="2">
<li>分别把P1,P2,P3以及T1,T2,T3合并，得到一个新的训练集和测试集train2,test2.<img src="/2018/06/29/Titanic_3/pic2.png" title="This is an example image"></li>
<li><p>再用第二层的模型M4训练train2,预测test2,得到最终的标签列。</p>
<img src="/2018/06/29/Titanic_3/pic3.png" title="This is an example image">
<p>说人话就是，3个学霸参加了1次会考,记下自己写的会考答案后直接参加高考，记下自己写的高考答案。然后拿自己写的会考的答案与真实会考答案拟合一下，根据自己写的高考答案预测高考真实答案。由于之前说了用整个训练集不仅对模型的选择来说是有风险的，而且也会有过拟的风险。所以，最好加上交叉验证。</p>
</li>
<li><p>以2折交叉验证得到P1为例,假设训练集为4行3列</p>
<img src="/2018/06/29/Titanic_3/pic4.png" title="This is an example image">
<p>将其划分为2部分</p>
<img src="/2018/06/29/Titanic_3/pic5.png" title="This is an example image">
<p>用traina训练模型M1，然后在trainb上进行预测得到preb3和pred4</p>
<img src="/2018/06/29/Titanic_3/pic6.png" title="This is an example image">
<p>在trainb上训练模型M1，然后在traina上进行预测得到pred1和pred2</p>
<img src="/2018/06/29/Titanic_3/pic7.png" title="This is an example image">
<p>然后把两个预测集进行拼接</p>
<img src="/2018/06/29/Titanic_3/pic8.png" title="This is an example image">
<p>对于测试集T1的得到，注意到刚刚是2折交叉验证，M1相当于在训练集上训练了2次，产生两组belta，然后在测试集上预测2次，然后对这两列求平均得到T1。说人话就是，3个学霸参加了10次月考,记下自己写的月考答案后直接参加高考，然后拿月考的答案与真实的月考答案拟合一下，根据自己写的高考答案预测高考真实答案。</p>
<h3 id="六、Stacking的相关问题"><a href="#六、Stacking的相关问题" class="headerlink" title="六、Stacking的相关问题"></a>六、Stacking的相关问题</h3><p>为什么用stacking，而不是投票？<br>问题:为什么最好不用整个训练数据做训练？过拟？<br>很多说法是整个训练集做训练来预测测试集的标签会导致过拟。这看似给出了答案，这样做不好的原因是会过拟，但并没有解释过拟的原因。我想知道的是用整个训练集做训练是怎么导致过拟的。</p>
<h3 id="所以我们的第1个问题应该是：整个训练集做训练是如何导致过拟？"><a href="#所以我们的第1个问题应该是：整个训练集做训练是如何导致过拟？" class="headerlink" title="所以我们的第1个问题应该是：整个训练集做训练是如何导致过拟？"></a>所以我们的第1个问题应该是：整个训练集做训练是如何导致过拟？</h3><p>说到这个，又使我想到很多说法都说交叉验证可以解决这个问题，所以通常我们看到模型训练的时候一般都会使用交叉验证。我们都知道的是交叉验证是把整个训练集分成K份，K-1份作为训练，剩下的一份作为预测。</p>
<h3 id="所以我们这里又产生第2个问题：将训练集分成K份做训练，能解决过拟吗？"><a href="#所以我们这里又产生第2个问题：将训练集分成K份做训练，能解决过拟吗？" class="headerlink" title="所以我们这里又产生第2个问题：将训练集分成K份做训练，能解决过拟吗？"></a>所以我们这里又产生第2个问题：将训练集分成K份做训练，能解决过拟吗？</h3><p>而这两个问题是相关的，了解交叉验证是如何解决过拟这个问题（即交叉验证是弥补了什么缺点）也就意味着了解了为什么用整个训练集做训练会过拟。</p>
</li>
</ol>
<p>我们都知道的是在sklearn中要用交叉验证需要从sklearn.model_selection中调用cross_val_score函数<br>而之前一直不太明白是为什么交叉验证是作为模型选择的，以前一直觉得是一种训练模型的方式。其实，它的本质是为了评估模型的稳定性。举个例子：在Dota世界杯之前，每个俱乐部都想了解自己队员的实力以便决定是不是要做人员调整，有的队伍会选择打10个小型比赛，而有的队伍会选择不参加平时的小比赛只在世界杯前参一场大赛来评估水平。而这时，像三冰这样发挥不太稳定的选手，他有可能因为对Majior的那个版本了解深刻，所以准备的特别好，从而拿到了冠军。然而却在TI时，发挥失力。而其它参加minor的队伍，由于有了10场比赛的数据，他们也心里有了B数知道自己的水平是稳定的，到时候只要正常发挥就好了。<br>这也就是为什么一般都会选交叉验证，毕竟是做工业的要得就是稳定的模型。如果用整个训练集训练然后直接用在测试集上，难保会有模型发挥失常。而交叉验证就相当于给模型多次证明自己的机会，然后取各自的平均分。所以用整个训练集来训练不仅对模型的选择来说是有风险的，而且也会有过拟的风险。</p>
<p>从中还想到一个估计暂时也不会去碰的问题，比如对一个模型做5折交叉验证会产生5个分数，模型的分数可以做平均。而最终这个模型拿去用在测试集上的时候，它里面训练的一5组belta是怎么取的，算平均吗？</p>
<h2 id="2-Titanic-Stacking-构建"><a href="#2-Titanic-Stacking-构建" class="headerlink" title="2 Titanic Stacking 构建"></a>2 Titanic Stacking 构建</h2><h3 id="一、设置训练集和测试集"><a href="#一、设置训练集和测试集" class="headerlink" title="一、设置训练集和测试集"></a>一、设置训练集和测试集</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#训练集</span></span><br><span class="line">x_train = train.drop([<span class="string">'Survived'</span>], axis=1).values</span><br><span class="line">y_train = train[<span class="string">'Survived'</span>].ravel()</span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">x_test = test.values</span><br></pre></td></tr></table></figure>
<h3 id="二、5折交叉验证"><a href="#二、5折交叉验证" class="headerlink" title="二、5折交叉验证"></a>二、5折交叉验证</h3><p>5个模型在训练集上预测标签（179，5） 以及测实集5次预测的平均（418，1）<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def get_oof(clf, x_train, y_train, x_test):</span><br><span class="line">      oof_train = np.zeros((ntrain,)) <span class="comment">#(891,)</span></span><br><span class="line">      oof_test = np.zeros((ntest,))   <span class="comment">#(418,)</span></span><br><span class="line">      oof_test_skf = np.empty((NFOLDS, ntest)) <span class="comment">#（5，418）</span></span><br><span class="line"></span><br><span class="line">     <span class="comment">#每个模型训练5次</span></span><br><span class="line">      <span class="keyword">for</span> i, (train_index, test_index) <span class="keyword">in</span> enumerate(kf):</span><br><span class="line">                              x_tr = x_train[train_index]<span class="comment">#(712, 5)</span></span><br><span class="line">                              y_tr = y_train[train_index]<span class="comment">#(712,)</span></span><br><span class="line">                              x_te = x_train[test_index]<span class="comment">#(179, 5)</span></span><br><span class="line">                           <span class="comment">#（训练集）训练其中4份数据</span></span><br><span class="line">                           clf.train(x_tr, y_tr)</span><br><span class="line"></span><br><span class="line">                            <span class="comment">#（训练集）预测剩下的第5份数据</span></span><br><span class="line">                           oof_train[test_index] = clf.predict(x_te)</span><br><span class="line"></span><br><span class="line">                            <span class="comment">#（测试集）预测5次测试集的数据</span></span><br><span class="line">                           oof_test_skf[i, :] = clf.predict(x_test)</span><br><span class="line">    <span class="comment">#将5次测试集的数据求平均</span></span><br><span class="line">    oof_test[:] = oof_test_skf.mean(axis=0)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)</span><br></pre></td></tr></table></figure></p>
<h3 id="三、每个模型5次叉验证得到预测标签合并为（891-1）"><a href="#三、每个模型5次叉验证得到预测标签合并为（891-1）" class="headerlink" title="三、每个模型5次叉验证得到预测标签合并为（891.1）"></a>三、每个模型5次叉验证得到预测标签合并为（891.1）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># Extra Trees：et_oof_train：(891, 1)， et_oof_test：(418, 1)</span></span><br><span class="line">et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Random Forest：rf_oof_train(891, 1) ，rf_oof_test(418, 1)</span></span><br><span class="line">rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test)</span><br><span class="line"></span><br><span class="line"> <span class="comment"># AdaBoost ada_oof_train：(891, 1) ，ada_oof_test(418, 1)</span></span><br><span class="line">ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Gradient Boost：gb_oof_train(891, 1) ，gb_oof_test(418, 1)</span></span><br><span class="line">gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Support Vector Classifier：svc_oof_train(891, 1)，svc_oof_test (418, 1)</span></span><br><span class="line">svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test)</span><br></pre></td></tr></table></figure>
<h3 id="四、将5个模型的预测值和测试值合并：x-train（891，5），x-test（418，5）"><a href="#四、将5个模型的预测值和测试值合并：x-train（891，5），x-test（418，5）" class="headerlink" title="四、将5个模型的预测值和测试值合并：x_train（891，5），x_test（418，5）"></a>四、将5个模型的预测值和测试值合并：x_train（891，5），x_test（418，5）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)</span><br><span class="line">x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)</span><br></pre></td></tr></table></figure>
<h3 id="五、将训练集的预测值（891，5）与真实值（891，1）作为输入，用XGB模型训练，预测测试集（418，5）"><a href="#五、将训练集的预测值（891，5）与真实值（891，1）作为输入，用XGB模型训练，预测测试集（418，5）" class="headerlink" title="五、将训练集的预测值（891，5）与真实值（891，1）作为输入，用XGB模型训练，预测测试集（418，5）"></a>五、将训练集的预测值（891，5）与真实值（891，1）作为输入，用XGB模型训练，预测测试集（418，5）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">gbm = xgb.XGBClassifier(</span><br><span class="line">    <span class="comment">#learning_rate = 0.02,</span></span><br><span class="line">    n_estimators= 2000,</span><br><span class="line">    max_depth= 4,</span><br><span class="line">    min_child_weight= 2,</span><br><span class="line">    <span class="comment">#gamma=1,</span></span><br><span class="line">    gamma=0.9,                        </span><br><span class="line">    subsample=0.8,</span><br><span class="line">    colsample_bytree=0.8,</span><br><span class="line">    objective= <span class="string">'binary:logistic'</span>,</span><br><span class="line">    nthread= -1,</span><br><span class="line">    scale_pos_weight=1).fit(x_train, y_train)</span><br><span class="line">predictions = gbm.predict(x_test)</span><br></pre></td></tr></table></figure>
<p>Reference:<br><a href="https://zhuanlan.zhihu.com/p/25836678" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25836678</a><br><a href="https://www.jiqizhixin.com/articles/2018-01-14-8" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2018-01-14-8</a><br><a href="https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/notebook" target="_blank" rel="noopener">https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python/notebook</a></p>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 valine -->
<div id="comment">
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script>
    new Valine({
        el: '#comment' ,
        notify: true,
        verify: false,
        app_id: '5ieD2qBIigoLuVa78tzFJ22P-gzGzoHsz',
        app_key: '6TREdEvvBJpk2ElJDUL27w5U',
        placeholder: 'Please leave your footprints',
        pageSize: '10',
        avatar: '',
        avatar_cdn: 'https://gravatar.loli.net/avatar/'
    });
</script>
</div>
<style>
   #comment{
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
            </ul>
            
            	<span id="busuanzi_container_site_pv">2018总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
