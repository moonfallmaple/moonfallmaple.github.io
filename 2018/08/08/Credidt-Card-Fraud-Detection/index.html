<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo.png"/>
	<link rel="shortcut icon" href="/img/logo.png">
	
			    <title>
    Moonfall Jade
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="" />
    
    	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
</head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">月明天清</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">Home</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">Category</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/Data-Analysis/">Data-Analysis</a>
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/tags/" title="Tag">
		                Tag
		            </a>
		        </li>
		        
		        <li>
		            <a href="https://www.linkedin.com/in/jane-shan-a50170142/" title="Resume">
		                Resume
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/sunrisejade" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height:8rem;background-image: url();background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 2rem 4rem 2rem 4rem ;"><h2 >Credit_Card_Fraud</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 2rem 4rem 2rem 4rem ;">
                <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.</p>
<p>It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are ‘Time’ and ‘Amount’. Feature ‘Time’ contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature ‘Amount’ is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature ‘Class’ is the response variable and it takes value 1 in case of fraud and 0 otherwise.</p>
<p>This report show how build a credit card fraud detection model.</p>
<h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><blockquote>
<p>1: Understanding our data</p>
</blockquote>
<blockquote>
<p>Exploring Data</p>
</blockquote>
<blockquote>
<p>Detect missing value</p>
</blockquote>
<blockquote>
<p>2:Feature Engineering</p>
</blockquote>
<blockquote>
<p>2.1: Creating ‘Hour’ Feature</p>
</blockquote>
<blockquote>
<p>2.2: Exploring patterns difference between Normal and Fraud Transanctions</p>
</blockquote>
<blockquote>
<p>2.3: Exploring feature distribution difference between Normal and Fraud transactions</p>
</blockquote>
<blockquote>
<p>2.4: Feature scaling with ‘Hour’ and ‘Amount’</p>
</blockquote>
<blockquote>
<p>2.5: Exploring feature importance</p>
</blockquote>
<blockquote>
<p>3: Splitting the Data (Original DataFrame)</p>
</blockquote>
<blockquote>
<p>4: Random Under-Sampling</p>
</blockquote>
<blockquote>
<p>5:Modeling</p>
</blockquote>
<blockquote>
<p>6:Evaluation</p>
</blockquote>
<h3 id="1-Understanding-our-data"><a href="#1-Understanding-our-data" class="headerlink" title="1: Understanding our data"></a>1: Understanding our data</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import matplotlib.gridspec as gridspec</span><br><span class="line"></span><br><span class="line"><span class="comment"># Classifier Libraries</span></span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">import collections</span><br></pre></td></tr></table></figure>
<p>Summary:<br>The transaction amount is relatively small. The mean of all the mounts made is approximately USD 88.<br>There are no “Null” values, so we don’t have to work on ways to replace values.<br>Most of the transactions were Non-Fraud (99.83%) of the time, while Fraud transactions occurs (017%) of the time in the dataframe</p>
<div align="center"><br><img src="./q1.png" width="843" height="424" alt="图片名称" align="center"><br></div>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">'Normal transactions:'</span>,round(data[<span class="string">'Class'</span>].value_counts()[0]/len(data[<span class="string">'Class'</span>])*100,2),</span><br><span class="line"><span class="string">'of the dataset'</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Fraud transactions:'</span>,round(data[<span class="string">'Class'</span>].value_counts()[1]/len(data[<span class="string">'Class'</span>])*100,2),</span><br><span class="line"><span class="string">'of the dataset'</span>)</span><br><span class="line"></span><br><span class="line">fig, axs = plt.subplots(1,2,figsize=(14,7))</span><br><span class="line">axs[0].set_title(<span class="string">"Frequency of each Class"</span>)</span><br><span class="line">data[<span class="string">'Class'</span>].value_counts().plot(kind=<span class="string">'bar'</span>,ax=axs[0])</span><br><span class="line"></span><br><span class="line">axs[1].set_title(<span class="string">"Percentage of each Class"</span>)</span><br><span class="line">data[<span class="string">'Class'</span>].value_counts().plot(kind=<span class="string">'pie'</span>,ax=axs[1])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="2-Feature-Engineering"><a href="#2-Feature-Engineering" class="headerlink" title="2.Feature Engineering"></a>2.Feature Engineering</h3><h4 id="2-1-Creating-‘Hour’-Feature"><a href="#2-1-Creating-‘Hour’-Feature" class="headerlink" title="2.1: Creating ‘Hour’ Feature"></a>2.1: Creating ‘Hour’ Feature</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">'Hour'</span>]=data[<span class="string">"Time"</span>].apply(lambda x : divmod(x, 3600)[0])</span><br></pre></td></tr></table></figure>
<h4 id="2-2-Exploring-patterns-difference-between-Normal-and-Fraud-Transanctions"><a href="#2-2-Exploring-patterns-difference-between-Normal-and-Fraud-Transanctions" class="headerlink" title="2.2:Exploring patterns difference between Normal and Fraud Transanctions"></a>2.2:Exploring patterns difference between Normal and Fraud Transanctions</h4><blockquote>
<p>Difference 1: For the fraud transactions: the correlation between some of the variables is more pronounced. The variation between V1, V2, V3, V4, V5, V6, V7, V9, V10, V11, V12, V14, V16, V17 and V18 and V19 presents a certain pattern</p>
</blockquote>
<div align="center"><br><img src="./q2.png" width="906" height="594" alt="图片名称" align="center"><br></div>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Xfraud = data.loc[data[<span class="string">"Class"</span>] == 1] <span class="comment"># update Xfraud &amp; XnonFraud with cleaned data</span></span><br><span class="line">XnonFraud = data.loc[data[<span class="string">"Class"</span>] == 0]</span><br><span class="line"></span><br><span class="line">correlationNonFraud = XnonFraud.loc[:, data.columns != <span class="string">'Class'</span>].corr()</span><br><span class="line"></span><br><span class="line">mask = np.zeros_like(correlationNonFraud) <span class="comment"># boolean array</span></span><br><span class="line">indices = np.triu_indices_from(correlationNonFraud) <span class="comment">#Return the indices for the</span></span><br><span class="line">upper-triangle of arr.</span><br><span class="line">mask[indices] = True</span><br><span class="line">grid_kws = &#123;<span class="string">"width_ratios"</span>: (.9, .9, .05), <span class="string">"wspace"</span>: 0.2&#125;</span><br><span class="line">f, (ax1, ax2, cbar_ax) = plt.subplots(1, 3, gridspec_kw=grid_kws, figsize = (14, 9))</span><br><span class="line"></span><br><span class="line">cmap = sns.diverging_palette(220, 8, as_cmap=True) <span class="comment">#color map</span></span><br><span class="line">ax1 =sns.heatmap(correlationNonFraud, ax = ax1, vmin = -1, vmax = 1, cmap = cmap,</span><br><span class="line">square = False, linewidths = 0.5, mask = mask, cbar = False)</span><br><span class="line">ax1.set_xticklabels(ax1.get_xticklabels(), size = 16);</span><br><span class="line">ax1.set_yticklabels(ax1.get_yticklabels(), size = 16);</span><br><span class="line">ax1.set_title(<span class="string">'Normal'</span>, size = 20)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">correlationFraud = Xfraud.loc[:, data.columns != <span class="string">'Class'</span>].corr()</span><br><span class="line">ax2 = sns.heatmap(correlationFraud, vmin = -1, vmax = 1, cmap = cmap, \</span><br><span class="line">      ax = ax2, square = False, linewidths = 0.5, mask = mask, yticklabels = False, \</span><br><span class="line">      cbar_ax = cbar_ax, cbar_kws=&#123;<span class="string">'orientation'</span>: <span class="string">'vertical'</span>, \</span><br><span class="line">                                 <span class="string">'ticks'</span>: [-1, -0.5, 0, 0.5, 1]&#125;)</span><br><span class="line">ax2.set_xticklabels(ax2.get_xticklabels(), size = 16);</span><br><span class="line">ax2.set_title(<span class="string">'Fraud'</span>, size = 20);</span><br><span class="line"></span><br><span class="line">cbar_ax.set_yticklabels(cbar_ax.get_yticklabels(), size = 14)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Difference 2: Fraud transactions tend to be Small Amount</p>
</blockquote>
<div align="center"><br><img src="./q22.png" width="848" height="333" alt="图片名称" align="center"><br></div>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, sharey=True,figsize = (14, 5))</span><br><span class="line"></span><br><span class="line">sns.distplot(data[data[<span class="string">'Class'</span>]==1][<span class="string">'Amount'</span>], ax=ax0, bins=30)</span><br><span class="line">ax0.set(title=<span class="string">"Fraud"</span>,xlabel=<span class="string">'Amount ($)'</span>,ylabel=<span class="string">'Probability'</span>)</span><br><span class="line"></span><br><span class="line">sns.distplot(data[data[<span class="string">'Class'</span>]==0][<span class="string">'Amount'</span>], ax=ax1, bins=30)</span><br><span class="line">ax1.set(title=<span class="string">"Normal"</span>,xlabel=<span class="string">'Amount ($)'</span>,ylabel=<span class="string">'Probability'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Difference 3: The most frequent fraud transactions were happended at 11:am on the first day. The rest of Fraud transactions were happened between 11pm-9am. Indicating that the credit theft don’t want to attract the credit card owner’s attention, so they prefer to choose the time when the owner sleep and the time when consumption frequency is high.</p>
</blockquote>
<div align="center"><br><img src="./q23.png" width="1302" height="424" alt="图片名称" align="center"><br></div>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># High Consumption frequency: between 9:00 am to 11:00 pm</span></span><br><span class="line">sns.factorplot(x=<span class="string">'Hour'</span>,data=data,kind=<span class="string">"count"</span>,  palette=<span class="string">"ocean"</span>, size=6, aspect=3)</span><br></pre></td></tr></table></figure>
<div align="center"><br><img src="./q24.png" width="956" height="333" alt="图片名称" align="center"><br></div>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig,(ax0, ax1) = plt.subplots(nrows=1, ncols=2,figsize = (16, 5))</span><br><span class="line">ax0.scatter(data[data[<span class="string">'Class'</span>]==1][<span class="string">'Hour'</span>],data[data[<span class="string">'Class'</span>]==1][<span class="string">'Amount'</span>])</span><br><span class="line">ax0.set(title=<span class="string">'Fraud'</span>,xlabel=<span class="string">'Hour'</span>,ylabel=<span class="string">'Amount($)'</span>)</span><br><span class="line"></span><br><span class="line">ax1.scatter(data[data[<span class="string">'Class'</span>]==0][<span class="string">'Hour'</span>],data[data[<span class="string">'Class'</span>]==0][<span class="string">'Amount'</span>])</span><br><span class="line">ax1.set(title=<span class="string">'Normal'</span>,xlabel=<span class="string">'Hour'</span>,ylabel=<span class="string">'Amount($)'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="2-3-Exploring-feature-distribution-difference-between-Normal-and-Fraud-transactions"><a href="#2-3-Exploring-feature-distribution-difference-between-Normal-and-Fraud-transactions" class="headerlink" title="2.3: Exploring feature distribution difference between Normal and Fraud transactions"></a>2.3: Exploring feature distribution difference between Normal and Fraud transactions</h4><p>Figures below present the distribution of different variables between Normal and Fraud,we should choose those variables which has significant difference.<br>We drop variables:’V8’, ‘V13’, ‘V15’, ‘V20’, ‘V21’, ‘V22’, ‘V23’, ‘V24’, ‘V25’, ‘V26’, ‘V27’, ‘V28’</p>
<div align="center"><br><img src="./q25.png" width="939" height="1678" alt="图片名称" align="center"><br></div>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">features_name=data.iloc[:,1:29].columns</span><br><span class="line">features_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># define the figsize of the whole picture</span></span><br><span class="line">plt.figure(figsize=(16,30))</span><br><span class="line"></span><br><span class="line"><span class="comment"># define the num of columns and rows</span></span><br><span class="line">gs = gridspec.GridSpec(7, 4)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i,f <span class="keyword">in</span> enumerate(data[features_name]):</span><br><span class="line">    ax = plt.subplot(gs[i])</span><br><span class="line">    sns.distplot(data[f][data[<span class="string">"Class"</span>] == 1], bins=50)</span><br><span class="line">    sns.distplot(data[f][data[<span class="string">"Class"</span>] == 0], bins=50)</span><br><span class="line">    ax.set_xlabel(<span class="string">''</span>)</span><br><span class="line">    ax.set_title(<span class="string">'histogram of feature: '</span> + str(f))</span><br></pre></td></tr></table></figure>
<p>Generate a new dataframe “data_new”<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">droplist = [<span class="string">'V8'</span>, <span class="string">'V13'</span>, <span class="string">'V15'</span>, <span class="string">'V20'</span>, <span class="string">'V21'</span>, <span class="string">'V22'</span>, <span class="string">'V23'</span>, <span class="string">'V24'</span>, <span class="string">'V25'</span>, <span class="string">'V26'</span>, <span class="string">'V27'</span>, <span class="string">'V28'</span>,<span class="string">'Time'</span>]</span><br><span class="line">data_new = data.drop(droplist, axis = 1)</span><br><span class="line">data_new.shape <span class="comment"># 查看数据的维度</span></span><br><span class="line">data_new.head()</span><br></pre></td></tr></table></figure></p>
<h4 id="2-4-Feature-scaling-with-‘Hour’-and-‘Amount’"><a href="#2-4-Feature-scaling-with-‘Hour’-and-‘Amount’" class="headerlink" title="2.4: Feature scaling with ‘Hour’ and ‘Amount’"></a>2.4: Feature scaling with ‘Hour’ and ‘Amount’</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Feature scaling with 'Amount' and 'Hour'</span></span><br><span class="line">col = [<span class="string">'Amount'</span>,<span class="string">'Hour'</span>]</span><br><span class="line">from sklearn.preprocessing import StandardScaler <span class="comment"># 导入模块</span></span><br><span class="line">sc =StandardScaler() <span class="comment"># 初始化缩放器</span></span><br><span class="line">data_new[col] =sc.fit_transform(data_new[col])<span class="comment">#对数据进行标准化</span></span><br><span class="line">data_new.head()</span><br></pre></td></tr></table></figure>
<h4 id="2-5-Exploring-feature-importance"><a href="#2-5-Exploring-feature-importance" class="headerlink" title="2.5: Exploring feature importance"></a>2.5: Exploring feature importance</h4><div align="center"><br><img src="./q26.png" width="385" height="587" alt="图片名称" align="center"><br></div><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入库</span></span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">import plotly.offline as py</span><br><span class="line">py.init_notebook_mode(connected=True)</span><br><span class="line">import plotly.graph_objs as go</span><br><span class="line">import plotly.tools as tls</span><br><span class="line"></span><br><span class="line">X_columns=data_new.drop([<span class="string">'Class'</span>], axis=1).columns</span><br><span class="line">X_value= data_new.drop([<span class="string">'Class'</span>], axis=1)</span><br><span class="line">y_value=data_new[<span class="string">'Class'</span>]</span><br><span class="line">rf=RandomForestClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">rf.fit(X_value,y_value)</span><br><span class="line"></span><br><span class="line"><span class="comment">#预测特征重要度</span></span><br><span class="line">rf_features =rf.feature_importances_</span><br><span class="line"></span><br><span class="line">cols = X_columns.values</span><br><span class="line">feature_dataframe = pd.DataFrame( &#123;<span class="string">'features'</span>: cols,<span class="string">'Random Forest feature importances'</span>: rf_features&#125;)</span><br><span class="line">feature_dataframe.sort_values(by=<span class="string">'Random Forest feature importances'</span>,ascending=False)</span><br></pre></td></tr></table></figure><br><br>### 3: Splitting the Data (Original DataFrame)<br>Before proceeding with the Random UnderSampling technique we have to separate the orginal dataframe.<br> Why? for testing purposes, we want to test our models on the original testing set not on the testing set created by either of UnderSampling or Oversampling techniques. The main goal is to fit the model either with the dataframes that were undersample and oversample (in order for our models to detect the patterns), and test it on the original testing set.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.model_selection import StratifiedShuffleSplit</span><br><span class="line">sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> sss.split(X_value, y_value):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"Train:"</span>, train_index, <span class="string">"Test:"</span>, test_index)</span><br><span class="line">    original_Xtrain, original_Xtest = X_value.iloc[train_index],X_value.iloc[test_index]</span><br><span class="line">    original_ytrain, original_ytest = y_value.iloc[train_index],y_value.iloc[test_index]</span><br><span class="line"><span class="built_in">print</span>(original_Xtrain.shape)</span><br><span class="line"><span class="built_in">print</span>(original_Xtest.shape)</span><br><span class="line"><span class="built_in">print</span>(original_ytrain.shape)</span><br><span class="line"><span class="built_in">print</span>(original_ytest.shape)</span><br><span class="line"><span class="built_in">print</span>(original_ytrain.value_counts()[0]/len(original_ytrain),original_ytrain.value_counts()[1]/</span><br><span class="line">len(original_ytrain))</span><br><span class="line"><span class="built_in">print</span>(original_ytest.value_counts()[0]/len(original_ytest),original_ytest.value_counts()[1]/</span><br><span class="line">len(original_ytest))</span><br><span class="line"></span><br><span class="line">Train: [265518 180305  42664 ...  29062  13766  17677] Test: [263020  11378 147283 ... 274532</span><br><span class="line"> 269819  64170]</span><br><span class="line">Train: [ 72227 114282  16818 ... 264471 191914 284017] Test: [202638  32978 128121 ... 244024</span><br><span class="line">127667  48318]</span><br><span class="line">Train: [ 20895 114622 167683 ... 244502 178972 218506] Test: [284352  82483  90981 ... 171224</span><br><span class="line">168807 271602]</span><br><span class="line">Train: [122248 181660 194400 ... 104631 277586  29432] Test: [225673  63348  68025 ... 279451</span><br><span class="line"> 77554  76043]</span><br><span class="line">Train: [241684 223467 136928 ...  86495 160550  49633] Test: [157557 204860  83760 ... 251478</span><br><span class="line"> 178967 216850]</span><br><span class="line">(227845, 18)</span><br><span class="line">(56962, 18)</span><br><span class="line">(227845,)</span><br><span class="line">(56962,)</span><br><span class="line"></span><br><span class="line">0.9982707542408216 0.001729245759178389</span><br><span class="line">0.9982795547909132 0.0017204452090867595</span><br></pre></td></tr></table></figure><br><br>### 4: Random Under-Sampling<br><div align="center"><br><img src="./q4.png" width="392" height="279" alt="图片名称" align="center"><br></div>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Since our classes are highly skewed we should make them equivalent in order to</span></span><br><span class="line"> have balanced classes.</span><br><span class="line"></span><br><span class="line"><span class="comment"># Lets shuffle the data before creating the subsamples</span></span><br><span class="line"></span><br><span class="line">data_new = data_new.sample(frac=1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># amount of fraud classes 492 rows.</span></span><br><span class="line">fraud_df = data_new.loc[data_new[<span class="string">'Class'</span>] == 1]</span><br><span class="line">non_fraud_df = data_new.loc[data_new[<span class="string">'Class'</span>] == 0][:492]</span><br><span class="line"></span><br><span class="line">normal_distributed_df = pd.concat([fraud_df, non_fraud_df])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Shuffle dataframe rows</span></span><br><span class="line">new_df = normal_distributed_df.sample(frac=1, random_state=42)</span><br><span class="line"></span><br><span class="line">new_df.head()</span><br><span class="line"></span><br><span class="line">sns.countplot(new_df[<span class="string">'Class'</span>])</span><br><span class="line">plt.title(<span class="string">'Equally Distributed Classes'</span>, fontsize=14)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 valine -->
<div id="comment">
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script>
    new Valine({
        el: '#comment' ,
        notify: true,
        verify: false,
        app_id: '5ieD2qBIigoLuVa78tzFJ22P-gzGzoHsz',
        app_key: '6TREdEvvBJpk2ElJDUL27w5U',
        placeholder: 'Please leave your footprints',
        pageSize: '10',
        avatar: '',
        avatar_cdn: 'https://gravatar.loli.net/avatar/'
    });
</script>
</div>
<style>
   #comment{
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
            </ul>
            
            	<span id="busuanzi_container_site_pv">2018总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
